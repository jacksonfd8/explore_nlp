{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #1: Machine Learning and Text Analysis (suggested time: 60-90m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Explore Data\n",
    "2. Build Classifier (initial model)\n",
    "3. Measure Results (initial model)\n",
    "4. Predict group membership for unlabeled tweets **[Task A]**\n",
    "5. Understand content of posts between Group 1 and Group 2 **[Task B]**\n",
    "6. Summary of Project + Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>#Job #Boston Site Supervisor / Lead Carpenter:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @wilw NBC reporting suspect alive and in cu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#BostonMararthon suspect Dzhokhar Tsarnaev is ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>THANK YOU ?MT @Boston_Police: CAPTURED! The hu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @CNBCClosingBell The Boston College Center ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Diversity: BU President To Testify Before The ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RT @BreitbartNews Margaret Thatcher Remembered...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@barstoolsports ?@barstoolsports: Some tremend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@itsYONAS thanks for the music man had this sh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  #Job #Boston Site Supervisor / Lead Carpenter:...    NaN\n",
       "1  RT @wilw NBC reporting suspect alive and in cu...    1.0\n",
       "2  #BostonMararthon suspect Dzhokhar Tsarnaev is ...    1.0\n",
       "3  THANK YOU ?MT @Boston_Police: CAPTURED! The hu...    NaN\n",
       "4  RT @CNBCClosingBell The Boston College Center ...    NaN\n",
       "5  Diversity: BU President To Testify Before The ...    NaN\n",
       "6  RT @BreitbartNews Margaret Thatcher Remembered...    1.0\n",
       "7  @Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...    NaN\n",
       "8  @barstoolsports ?@barstoolsports: Some tremend...    NaN\n",
       "9  @itsYONAS thanks for the music man had this sh...    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice some NaN values, let's see how many rows are missing from entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data, Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "label    12218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24663953631767171"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems we have missing LABEL data. What is percentage of missing data?\n",
    "df['label'].count() / len(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ensure we keep a dataframe of those with no labels, we will need this for later (Prediction Task)\n",
    "missing_vals_df = df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've stored the missing rows into a separate dataframe, \n",
    "# we can drop them from our initial model\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2000\n",
       "1.0    2000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if classes are balanced. Unbalanced classes will require some additional work.\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, balanced!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ensure we have hold-out set to predict on! or we may overfit.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Classifier (initial model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_clf = Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                        ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = twitter_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Results (initial model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[668   3]\n",
      " [  2 647]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962121212121212\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.6% accuracy score is great! Given our classes are balanced (50-50), \"accuracy\" score is a solid evaluation criteria. \n",
    "\n",
    "If our classes were imbalanced, we could have utilized precision-recall as our evaluation critiera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict group membership for unlabeled tweets (Task A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize existing model (of 99.6% accuracy score) to predict on the rest of dataset with missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>#Job #Boston Site Supervisor / Lead Carpenter:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>THANK YOU ?MT @Boston_Police: CAPTURED! The hu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @CNBCClosingBell The Boston College Center ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Diversity: BU President To Testify Before The ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16211</td>\n",
       "      <td>@MzSexxyJas We could be looking at 3 feet of s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16213</td>\n",
       "      <td>\"@MsStacyThatsMe: @4evergraceJONES Lol We're C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16214</td>\n",
       "      <td>RT @BostonDotCom This is according to @AP : Su...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16216</td>\n",
       "      <td>Thanks RT @laVisualiza: Boston is truly a beau...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16217</td>\n",
       "      <td>@chelseahandler, you're a class act. #PrayForB...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      #Job #Boston Site Supervisor / Lead Carpenter:...    NaN\n",
       "3      THANK YOU ?MT @Boston_Police: CAPTURED! The hu...    NaN\n",
       "4      RT @CNBCClosingBell The Boston College Center ...    NaN\n",
       "5      Diversity: BU President To Testify Before The ...    NaN\n",
       "7      @Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...    NaN\n",
       "...                                                  ...    ...\n",
       "16211  @MzSexxyJas We could be looking at 3 feet of s...    NaN\n",
       "16213  \"@MsStacyThatsMe: @4evergraceJONES Lol We're C...    NaN\n",
       "16214  RT @BostonDotCom This is according to @AP : Su...    NaN\n",
       "16216  Thanks RT @laVisualiza: Boston is truly a beau...    NaN\n",
       "16217  @chelseahandler, you're a class act. #PrayForB...    NaN\n",
       "\n",
       "[12218 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring back the set-aside df from earlier\n",
    "missing_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for modeling\n",
    "missing_vals_X = missing_vals_df['text'] \n",
    "missing_vals_y = missing_vals_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vals_predictions = twitter_clf.predict(missing_vals_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing value predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vals_df['label'] = list(pd.Series(missing_vals_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>#Job #Boston Site Supervisor / Lead Carpenter:...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>THANK YOU ?MT @Boston_Police: CAPTURED! The hu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @CNBCClosingBell The Boston College Center ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Diversity: BU President To Testify Before The ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16211</td>\n",
       "      <td>@MzSexxyJas We could be looking at 3 feet of s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16213</td>\n",
       "      <td>\"@MsStacyThatsMe: @4evergraceJONES Lol We're C...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16214</td>\n",
       "      <td>RT @BostonDotCom This is according to @AP : Su...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16216</td>\n",
       "      <td>Thanks RT @laVisualiza: Boston is truly a beau...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16217</td>\n",
       "      <td>@chelseahandler, you're a class act. #PrayForB...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      #Job #Boston Site Supervisor / Lead Carpenter:...    0.0\n",
       "3      THANK YOU ?MT @Boston_Police: CAPTURED! The hu...    1.0\n",
       "4      RT @CNBCClosingBell The Boston College Center ...    0.0\n",
       "5      Diversity: BU President To Testify Before The ...    0.0\n",
       "7      @Kid_Ink \\nNEW MUSIC @DubbZeroBFMI ft @TroyAve...    0.0\n",
       "...                                                  ...    ...\n",
       "16211  @MzSexxyJas We could be looking at 3 feet of s...    0.0\n",
       "16213  \"@MsStacyThatsMe: @4evergraceJONES Lol We're C...    1.0\n",
       "16214  RT @BostonDotCom This is according to @AP : Su...    1.0\n",
       "16216  Thanks RT @laVisualiza: Boston is truly a beau...    0.0\n",
       "16217  @chelseahandler, you're a class act. #PrayForB...    1.0\n",
       "\n",
       "[12218 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure new labeled data is consistent with original labeled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Two is asking us to look at the content of the posts between Group 1 and 2, but it would be good to check to see if the prediction labels we added are consistent across the original labeled data and the now, newly labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a function that will require top words and their frequency count\n",
    "\n",
    "def get_top_words(corpus, n=None):\n",
    "    \n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    words_sum = bag_of_words.sum(axis=0) \n",
    "    \n",
    "    words_freq = [(w, words_sum[0, idx]) for w, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original and Missing Value (Group 1 and Group 2) DFs\n",
    "og_group1 = df[df['label'] == 1]\n",
    "og_group2 = df[df['label'] == 0]\n",
    "mv_group1 = missing_vals_df[missing_vals_df['label'] == 1]\n",
    "mv_group2 = missing_vals_df[missing_vals_df['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 words for each respective group\n",
    "og_group1_tw = get_top_words(og_group1['text'], 10)\n",
    "mv_group1_tw = get_top_words(mv_group1['text'], 10)\n",
    "og_group2_tw = get_top_words(og_group2['text'], 10)\n",
    "mv_group2_tw = get_top_words(mv_group2['text'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Originally Labeled, Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 1090),\n",
       " ('http', 660),\n",
       " ('prayforboston', 615),\n",
       " ('boston', 568),\n",
       " ('watertown', 541),\n",
       " ('tsarnaev', 311),\n",
       " ('attack', 259),\n",
       " ('dzhokhar', 231),\n",
       " ('suspect', 207),\n",
       " ('terrorist', 173)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_group1_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newly Labeled, Group 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 2685),\n",
       " ('http', 1734),\n",
       " ('prayforboston', 1545),\n",
       " ('watertown', 1439),\n",
       " ('boston', 1431),\n",
       " ('tsarnaev', 684),\n",
       " ('attack', 633),\n",
       " ('dzhokhar', 500),\n",
       " ('suspect', 477),\n",
       " ('terror', 465)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_group1_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Originally Labeled, Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', 2299),\n",
       " ('http', 1531),\n",
       " ('rt', 453),\n",
       " ('job', 410),\n",
       " ('ma', 319),\n",
       " ('jobs', 113),\n",
       " ('celtics', 100),\n",
       " ('time', 82),\n",
       " ('cambridge', 80),\n",
       " ('new', 79)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_group2_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newly Labeled, Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', 8174),\n",
       " ('http', 5623),\n",
       " ('rt', 1471),\n",
       " ('job', 1467),\n",
       " ('ma', 1091),\n",
       " ('jobs', 376),\n",
       " ('new', 311),\n",
       " ('celtics', 294),\n",
       " ('news', 290),\n",
       " ('time', 248)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_group2_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content across original and newly labeled Tweets appear consistent for Groups 1 and 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understand content of posts between Group 1 and Group 2 (Task B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client cares about the differences between Group 1 and Group 2. I think an easy way to paint the picture is by looking at top words used in Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original df (with labels) with newly-classified df\n",
    "group1 = pd.concat([mv_group1, og_group1])\n",
    "group2 = pd.concat([mv_group2, og_group2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>THANK YOU ?MT @Boston_Police: CAPTURED! The hu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>RT @RevEverett #interfaith love song: Trinity ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Researchers urge brain autopsy of bombing susp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>RT @causeOlasaidso no matter how much goes dow...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Like this self-righteous piece of shit didn't ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16190</td>\n",
       "      <td>RT @bommadog That awkward moment when Twitter ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16192</td>\n",
       "      <td>RT @paulaebbenwbz: Source: talk of bringing in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16199</td>\n",
       "      <td>Crowds cheering tactical teams coming out of F...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16212</td>\n",
       "      <td>RT @Karmaloopboston Updated photo of 19 year-o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16215</td>\n",
       "      <td>CBS: FBI is leaning toward the #BostonMarathon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "3      THANK YOU ?MT @Boston_Police: CAPTURED! The hu...    1.0\n",
       "13     RT @RevEverett #interfaith love song: Trinity ...    1.0\n",
       "16     Researchers urge brain autopsy of bombing susp...    1.0\n",
       "18     RT @causeOlasaidso no matter how much goes dow...    1.0\n",
       "19     Like this self-righteous piece of shit didn't ...    1.0\n",
       "...                                                  ...    ...\n",
       "16190  RT @bommadog That awkward moment when Twitter ...    1.0\n",
       "16192  RT @paulaebbenwbz: Source: talk of bringing in...    1.0\n",
       "16199  Crowds cheering tactical teams coming out of F...    1.0\n",
       "16212  RT @Karmaloopboston Updated photo of 19 year-o...    1.0\n",
       "16215  CBS: FBI is leaning toward the #BostonMarathon...    1.0\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 20 words for both groups\n",
    "group1_tw = get_top_words(group1['text'], 20)\n",
    "group2_tw = get_top_words(group2['text'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt 3775\n",
      "http 2394\n",
      "prayforboston 2160\n",
      "boston 1999\n",
      "watertown 1980\n",
      "tsarnaev 995\n",
      "attack 892\n",
      "dzhokhar 731\n",
      "suspect 684\n",
      "terror 635\n",
      "marathon 595\n",
      "terrorist 581\n",
      "police 491\n",
      "bostonmarathon 378\n",
      "people 364\n",
      "bostonstrong 361\n",
      "just 318\n",
      "bombing 301\n",
      "manhunt 291\n",
      "news 268\n"
     ]
    }
   ],
   "source": [
    "for word, freq in group1_tw:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston 10473\n",
      "http 7154\n",
      "rt 1924\n",
      "job 1877\n",
      "ma 1410\n",
      "jobs 489\n",
      "celtics 394\n",
      "new 390\n",
      "news 361\n",
      "time 330\n",
      "cambridge 327\n",
      "manager 325\n",
      "https 277\n",
      "bos 271\n",
      "today 254\n",
      "engineer 246\n",
      "day 240\n",
      "nba 239\n",
      "city 236\n",
      "looking 209\n"
     ]
    }
   ],
   "source": [
    "for word, freq in group2_tw:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINDINGS\n",
    "- **GROUP 1 (group of interest)** Tweets were related to the Boston Marathon bombings.\n",
    "- **GROUP 2** Tweets were on subjects such as sports (celtics, nba) and job-hunt related topics (jobs, manager, engineer, looking)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Project + Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I initially discover that 75% of the data is missing. Fortunately, 25% of the data (4000 observations) was labeled with **balanced** classes.\n",
    "- I utilized my 99.6% accuracy model to label the rest of the missing label data.\n",
    "- We find that GROUP 1 Tweets were related to the Boston Marathon bombings, while GROUP 2 Tweets were related to Sports and Job-Hunting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If I had more time .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It would have been fun to beautify/visualize (WordClouds) the word frequencies!\n",
    "- Would have been cool to do Sentiment Analysis and perhaps expand timeframe to deeply understand the Groups.\n",
    "    - Group 1 seems to be folks that frequently follow the news. I can probably confirm that if we got a larger scope of Tweets (across a larger timeframe). Perhaps we can advertise News Apps or offer discounted newspaper subscriptions to this audience.\n",
    "    - Group 2 can be seen as sports junkies, but we probably want a larger timeframe just to confirm if these are NBA-only fans or if they bleed Boston sports and Tweet about everything sports (MLB, NFL, NHL). If so, sports cable packages can be a targeted ad. \n",
    "    - Group 2 also includes job-hunters. But it would be interesting to see if this can be isolated to a smaller population (I see \"Cambridge\" as a keyword), so these Twitter users can possibly be students. Plenty of opportunity to share this data with headhunters or student aid/resume writer professionals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
